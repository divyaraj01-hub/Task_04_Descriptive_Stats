# -*- coding: utf-8 -*-
"""2024_tw_posts_president_scored_anon.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k_ag8zn0OVzjiYgJNQm057nb71QjYdnW

2024_tw_posts_president_scored_anon.csv Statistics
"""

import pandas as pd

path = "/content/2024_tw_posts_president_scored_anon.csv"

df = pd.read_csv(path, on_bad_lines='skip', engine='python')  # skip problematic lines
df.head()

import csv
import statistics
from collections import defaultdict, Counter

def is_number(val):
    try:
        float(val)
        return True
    except:
        return False

def load_csv(path):
    with open(path, 'r', encoding='utf-8') as f:
        return list(csv.DictReader(f))

def summarize_column(col_values):
    numeric = [float(v) for v in col_values if is_number(v)]
    if numeric:
        return {
            "count": len(numeric),
            "mean": round(statistics.mean(numeric), 2),
            "min": min(numeric),
            "max": max(numeric),
            "std_dev": round(statistics.stdev(numeric), 2) if len(numeric) > 1 else 0
        }
    else:
        return {
            "unique": len(set(col_values)),
            "most_common": Counter(col_values).most_common(1)[0]
        }

def summarize_dataset(data, label="Dataset"):
    print(f"\n--- Summary: {label} ---")
    for col in data[0]:
        values = [row[col] for row in data]
        summary = summarize_column(values)
        print(f"\nColumn: {col}")
        for k, v in summary.items():
            print(f"  {k}: {v}")
def group_by(data, keys):
    groups = defaultdict(list)
    for row in data:
        try:
            key = tuple(row[k] for k in keys)
            groups[key].append(row)
        except KeyError as e:
            print(f"Missing key in row: {e}")
    return groups


# MAIN
data = load_csv("2024_tw_posts_president_scored_anon.csv")
summarize_dataset(data)

# Grouped by post_id
grouped = group_by(data, ["id"])
for i, (k, rows) in enumerate(grouped.items()):
    if i >= 2: break
    summarize_dataset(rows, label=f"group post_id={k}")

import pandas as pd

df = pd.read_csv("2024_tw_posts_president_scored_anon.csv")

print("\n--- Descriptive Statistics ---")
print(df.describe(include='all'))

print("\n--- Unique Count and Most Frequent Values ---")
for col in df.columns:
    print(f"\nColumn: {col}")
    print(f"  Unique values: {df[col].nunique()}")
    if df[col].dtype == 'object':
        print(f"  Most frequent: {df[col].value_counts().idxmax()}")

# Only numeric columns
numeric_cols = df.select_dtypes(include='number').columns

print("\n--- Grouped by id")
grouped_post = df.groupby("id")[numeric_cols].agg(['count', 'mean', 'min', 'max', 'std'])
print(grouped_post.head(3))

import polars as pl

df = pl.read_csv("2024_tw_posts_president_scored_anon.csv")

print("\n--- Descriptive Statistics ---")
print(df.describe())

print("\n--- Unique and Most Frequent Values ---")
for col in df.columns:
    print(f"\nColumn: {col}")
    print(f"  Unique: {df[col].n_unique()}")
    try:
        most_common = df.group_by(col).count().sort("count", descending=True)[0, col]
        print(f"  Most Frequent: {most_common}")
    except:
        print("  Most Frequent: N/A")

# Only numeric columns
numeric_cols = [col for col, dtype in zip(df.columns, df.dtypes) if dtype in [pl.Float64, pl.Int64]]

print("\n--- Grouped by post_id ---")
grouped_post = df.group_by("id").agg([
    pl.count(),
    *[pl.mean(c).alias(f"{c}_mean") for c in numeric_cols],
    *[pl.min(c).alias(f"{c}_min") for c in numeric_cols],
    *[pl.max(c).alias(f"{c}_max") for c in numeric_cols],
    *[pl.std(c).alias(f"{c}_std") for c in numeric_cols]
])
print(grouped_post.head(3))